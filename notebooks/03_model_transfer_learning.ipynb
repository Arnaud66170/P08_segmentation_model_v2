{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f5db14",
   "metadata": {},
   "source": [
    "## Notebook : 03_model_transfer_learning.ipynb\n",
    "- Objectif : Comparer plusieurs mod√®les UNet avec backbones pr√©-entra√Æn√©s (Transfer Learning)\n",
    "# 1 - Imports & pr√©paration\n",
    "## 1.1 - Librairies standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c5ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d02d552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow version : 2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ TensorFlow version :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a044436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU dispo : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU dispo :\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560664d",
   "metadata": {},
   "source": [
    "## 1.2 - Ajout des dossiers src/ et scripts/ au PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f94c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path().resolve().parent  # on part du dossier du notebook\n",
    "src_path = project_root / \"src\"\n",
    "scripts_path = project_root / \"scripts\"\n",
    "\n",
    "for path in [src_path, scripts_path]:\n",
    "    if str(path) not in sys.path:\n",
    "        sys.path.append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522f14c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root = C:\\Users\\motar\\Desktop\\1-openclassrooms\\AI_Engineer\\1-projets\\P08\\P08_segmentation\n",
      "src_path = C:\\Users\\motar\\Desktop\\1-openclassrooms\\AI_Engineer\\1-projets\\P08\\P08_segmentation\\src\n"
     ]
    }
   ],
   "source": [
    "print(\"project_root =\", project_root)\n",
    "print(\"src_path =\", src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cfd5e9",
   "metadata": {},
   "source": [
    "### Lancer, dans une console s√©par√©e (windows):\n",
    "#### - nvidia-smi\n",
    "- Cela affichera :\n",
    "\n",
    "    - la charge GPU\n",
    "\n",
    "    - la m√©moire utilis√©e\n",
    "\n",
    "    - le nom du process Python en cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc146b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow version : 2.10.1\n",
      "üü¢ GPU d√©tect√© : /physical_device:GPU:0\n",
      "üîß GPU utilis√© : /device:GPU:0 | M√©moire : 4.5 GB\n"
     ]
    }
   ],
   "source": [
    "from gpu_setup import enable_gpu_boost\n",
    "enable_gpu_boost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e469d",
   "metadata": {},
   "source": [
    "## 1.3 - Configuration des chemins et environnement\n",
    "- Chemins relatifs depuis notebooks/, vers data/ √† la racine du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6a2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = project_root / \"data\" / \"processed\" / \"augmented\"\n",
    "outputs_dir = project_root / \"outputs\" / \"figures\"\n",
    "logs_dir = project_root / \"outputs\" / \"logs\"\n",
    "models_dir = project_root / \"models\"\n",
    "\n",
    "outputs_dir.mkdir(parents = True, exist_ok = True)\n",
    "logs_dir.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae46693",
   "metadata": {},
   "source": [
    "## 1.4 - Chargement du mouchard guardrail pour pr√©venir les erreurs li√©es √† l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23c2e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chemin OK : C:\\Users\\motar\\Desktop\\1-openclassrooms\\AI_Engineer\\1-projets\\P08\\P08_segmentation\\models\n",
      "‚úÖ Chemin OK : C:\\Users\\motar\\Desktop\\1-openclassrooms\\AI_Engineer\\1-projets\\P08\\P08_segmentation\\data\\processed\\augmented\\train.npz\n",
      "‚úÖ Chemin OK : C:\\Users\\motar\\Desktop\\1-openclassrooms\\AI_Engineer\\1-projets\\P08\\P08_segmentation\\data\\processed\\augmented\\val.npz\n",
      "‚úÖ Import OK : model_training.metrics\n",
      "‚úÖ Import OK : utils.viz_utils\n"
     ]
    }
   ],
   "source": [
    "from utils.guardrail import check_paths_exist, check_imports\n",
    "\n",
    "check_paths_exist([\n",
    "    models_dir,\n",
    "    data_dir / \"train.npz\",\n",
    "    data_dir / \"val.npz\"\n",
    "])\n",
    "\n",
    "check_imports([\n",
    "    \"model_training.metrics\",\n",
    "    \"utils.viz_utils\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c0755",
   "metadata": {},
   "source": [
    "## 1.5 - V√©rification de la validit√© des mod√®les sauvegard√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dede7f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Aucun fichier mod√®le .h5 trouv√© dans : C:\\Users\\motar\\Desktop\\1-openclassrooms\\AI_Engineer\\1-projets\\P08\\P08_segmentation\\models\n"
     ]
    }
   ],
   "source": [
    "from model_training.metrics import iou_score, dice_coef\n",
    "from utils.guardrail import check_models_validity\n",
    "\n",
    "check_models_validity(models_dir, custom_objects={\"iou_score\": iou_score, \"dice_coef\": dice_coef})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266366f",
   "metadata": {},
   "source": [
    "# 2 - Chargement des donn√©es pr√©-trait√©es (.npz)\n",
    "## 2.1 - Lecture des fichiers .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7828d099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Chargement des donn√©es .npz...\n",
      "\n",
      "‚úÖ Donn√©es charg√©es : (2380, 256, 256, 3) / (2380, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Chargement des donn√©es .npz...\")\n",
    "train = np.load(data_dir / \"train.npz\")\n",
    "val   = np.load(data_dir / \"val.npz\")\n",
    "\n",
    "X_train, Y_train = train[\"X\"], train[\"Y\"]\n",
    "X_val, Y_val     = val[\"X\"], val[\"Y\"]\n",
    "\n",
    "print(f\"\\n‚úÖ Donn√©es charg√©es : {X_train.shape} / {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cb666",
   "metadata": {},
   "source": [
    "# 3 - Import du module d'entra√Ænement multi-backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ab79e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training.train_unet_backbones import train_unet_with_backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd967b",
   "metadata": {},
   "source": [
    "# 4 - Configuration des tests\n",
    "## 4.1 - Liste des backbones √† tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b37a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbones = [\"vgg16\", \"mobilenetv2\", \"efficientnetb0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba724084",
   "metadata": {},
   "source": [
    "## 4.2 - Param√®tres communs √† tous les mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b5f035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'img_size': (256, 256),\n",
    "    'epochs': 40,\n",
    "    'batch_size': 4,\n",
    "    'use_early_stopping': True,\n",
    "    'force_retrain': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a530d84",
   "metadata": {},
   "source": [
    "# 5 - Entra√Ænement de tous les mod√®les + collecte des r√©sultats\n",
    "## 5.1 - Boucle d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9ec9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import clean_gpu_cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01f1c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e171cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Entra√Ænement du mod√®le UNet + VGG16...\n",
      "üßπ Cache GPU nettoy√©\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_unet_with_backbone() got multiple values for keyword argument 'force_retrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m force \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnetb0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# force_dict = {\"vgg16\": False, \"mobilenetv2\": False, \"efficientnetb0\": True}\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# force = force_dict.get(b, False)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m model, history \u001b[38;5;241m=\u001b[39m train_unet_with_backbone(\n\u001b[0;32m     16\u001b[0m     backbone_name\u001b[38;5;241m=\u001b[39mb,\n\u001b[0;32m     17\u001b[0m     X_train\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[0;32m     18\u001b[0m     Y_train\u001b[38;5;241m=\u001b[39mY_train,\n\u001b[0;32m     19\u001b[0m     X_val\u001b[38;5;241m=\u001b[39mX_val,\n\u001b[0;32m     20\u001b[0m     Y_val\u001b[38;5;241m=\u001b[39mY_val,\n\u001b[0;32m     21\u001b[0m     force_retrain\u001b[38;5;241m=\u001b[39mforce,        \u001b[38;5;66;03m# <-- on injecte ici le flag dynamique\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams                    \u001b[38;5;66;03m# <-- les autres param√®tres standards\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m val_iou \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_iou_score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     26\u001b[0m val_dice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_dice_coef\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: train_unet_with_backbone() got multiple values for keyword argument 'force_retrain'"
     ]
    }
   ],
   "source": [
    "for b in backbones:\n",
    "    print(f\"\\nüß™ Entra√Ænement du mod√®le UNet + {b.upper()}...\")\n",
    "\n",
    "    # Nettoyage GPU\n",
    "    clean_gpu_cache()\n",
    "    print(\"üßπ Cache GPU nettoy√©\")\n",
    "\n",
    "    # ‚ö†Ô∏è Gestion du force_retrain sp√©cifique √† chaque backbone\n",
    "    force_retrain = (b == \"efficientnetb0\")  # True uniquement pour efficientnetb0\n",
    "\n",
    "    model, history = train_unet_with_backbone(\n",
    "        backbone_name=b,\n",
    "        X_train=X_train,\n",
    "        Y_train=Y_train,\n",
    "        X_val=X_val,\n",
    "        Y_val=Y_val,\n",
    "        force_retrain=force_retrain,\n",
    "        img_size=params['img_size'],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'],\n",
    "        use_early_stopping=params['use_early_stopping']\n",
    "    )\n",
    "\n",
    "    val_iou = max(history[\"val_iou_score\"])\n",
    "    val_dice = max(history[\"val_dice_coef\"])\n",
    "    val_acc = max(history[\"val_accuracy\"])\n",
    "    train_time = len(history[\"loss\"])\n",
    "\n",
    "    results.append({\n",
    "        \"backbone\": b,\n",
    "        \"val_iou\": val_iou,\n",
    "        \"val_dice\": val_dice,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"epochs_run\": train_time\n",
    "    })\n",
    "\n",
    "    # Visualisation\n",
    "    print(f\"\\nüìä R√©sum√© interm√©diaire - {b.upper()} :\")\n",
    "    print(f\"IoU max       : {val_iou:.4f}\")\n",
    "    print(f\"Dice max      : {val_dice:.4f}\")\n",
    "    print(f\"Accuracy max  : {val_acc:.4f}\")\n",
    "    print(f\"Epochs effectu√©s : {train_time}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history[\"val_iou_score\"], label=\"val_iou_score\")\n",
    "    plt.plot(history[\"val_dice_coef\"], label=\"val_dice_coef\")\n",
    "    plt.title(f\"{b.upper()} - IoU & Dice\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outputs_dir / f\"curve_iou_dice_{b}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5edc9f6",
   "metadata": {},
   "source": [
    "# 6 - Synth√®se comparative des performances\n",
    "## 6.1 - Visualisation tabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4385c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "display(results_df.sort_values(by = \"val_iou\", ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314cbc4",
   "metadata": {},
   "source": [
    "## 6.2 - Export CSV + log interm√©diaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13208d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(logs_dir / \"backbones_runs.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3575a6",
   "metadata": {},
   "source": [
    "## 6.3 - Visualisation graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(results_df[\"backbone\"], results_df[\"val_iou\"], color='cornflowerblue')\n",
    "plt.title(\"Comparaison des IoU par backbone\")\n",
    "plt.ylabel(\"Meilleur IoU\")\n",
    "plt.xlabel(\"Backbone\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outputs_dir / \"backbone_comparison_iou.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1b5f9",
   "metadata": {},
   "source": [
    "## 6.4 - Heatmap IoU vs Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_data = results_df.set_index(\"backbone\")[[\"val_iou\", \"val_dice\"]]\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(heat_data, annot=True, cmap=\"Blues\", fmt=\".3f\")\n",
    "plt.title(\"Heatmap : IoU vs Dice\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(outputs_dir / \"heatmap_iou_dice.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341359c",
   "metadata": {},
   "source": [
    "# 7 - S√©lection du meilleur mod√®le + pr√©paration pour Optuna\n",
    "## 7.1 - S√©lection automatique du backbone le plus performant (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.sort_values(by=\"val_iou\", ascending=False).iloc[0]\n",
    "best_backbone = best_row[\"backbone\"]\n",
    "print(f\"\\nüèÜ Meilleur backbone s√©lectionn√© automatiquement : {best_backbone.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec29dbf",
   "metadata": {},
   "source": [
    "## 7.2 - D√©clenchement d'un script Optuna personnalis√© (pr√©vu dans un fichier externe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_training.optimize_unet_with_optuna import run_optuna_for_backbone\n",
    "run_optuna_for_backbone(best_backbone, X_train, Y_train, X_val, Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
